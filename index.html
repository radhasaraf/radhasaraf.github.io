<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kenechukwu C. Mbanisi</title>
  
  <meta name="author" content="Kenechukwu C. Mbanisi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/kene.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kenechukwu C. Mbanisi</name>
              </p>
              <p>I am a PhD Candidate in the <a href="https://www.wpi.edu/academics/departments/robotics-engineering">Robotics Engineering prorgam</a> at Worcester Polytechnic Institute (WPI) where I work on shared autonomy and assisted driving for mobile robot navigation.
              </p>
              <p>
                I obtained my Masters degree in Robotics Engineering from WPI in May 2018, where I worked as a research assistant on a WPI-Toyota Research program on building an integrated active driver simulation framework
                for investigating human-vehicle interaction in semi- and fully-autonomous vehicles.
              </p>

              <p>
                I am passionate about STEM education and have worked on several programs such as: <a href="https://parcrobotics.org/">Pan-African Robotics Competition (PARC)</a>, <a href="https://arminstitute.org/projects/cobots-for-kids/"> Cobots For Kids</a> and
                <a href="https://www.wpi.edu/offices/provost/interdisciplinary-groups/global-initiatives/ms4ssa">Maths and Science for Sub-Saharan Africa (MS4SSA)</a>.
              </p>

              <p style="text-align:center">
                <a href="mailto:kene.mbanisi@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/kene-mbanisi-resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=vP-jd2gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/kenechukwu-mbanisi/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/kenembanisi">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kene_mbanisi.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/kene.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research & Projects</heading>
              <!-- <p>
                Projects with publications are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <!-- Learning socially-aware navigation behavior using imitation learning  -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/socnavassist.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Socially-Aware Navigation Behavior using Inverse Reinforcement Learning</papertitle>
              <br>
              <!-- <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
              <em>arXiv</em>, 2021 
              <br> -->
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2103.14645">arXiv</a> -->
              <!-- / -->
              <!-- <a href="https://kenembanisi.github.io/">arXiv</a>
              / -->
              <!-- <a href="https://kenembanisi.github.io/">project page</a> -->
              <p><em>(Ongoing Project)</em></p>
              <p></p>
              <p>Defining human-compatible social navigation constraints is complex. We leverage data-driven approach to learn the task constraints from expert (human) demonstrations.</p>
            </td>



          <!-- Robust mapping and socially-compliant navigation in warehouse environment  -->
          <!-- <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one"> -->
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <!-- <img src='images/shared_auto.gif' width="160"> -->
              <!-- </div>
            </td> -->
            <!-- <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Robust Mapping and Socially-Compliant Navigation in Warehouse Environment</papertitle>
              <br> -->
              <!-- <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
              <em>arXiv</em>, 2021 
              <br> -->
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2103.14645">arXiv</a> -->
              <!-- / -->
              <!-- <a href="https://kenembanisi.github.io/">arXiv</a>
              / -->
              <!-- <a href="https://kenembanisi.github.io/">project page</a> -->
              <!-- <p><em>(Ongoing Project)</em></p>
              <p></p>
              <p>Traditional 2D occupancy grid maps are limited in representing cluttered and dynamic environments. Robust feature-rich mapping and navigation is achieved by leveraging 3D maps of the environment.</p>
            </td> -->



          <!-- Shared autonomy for social robot navigation  -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/learning.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Shared Autonomy for Socially-Aware Robot Navigation</papertitle>
              <br>
              <!-- <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
              <em>arXiv</em>, 2021 
              <br> -->
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2103.14645">arXiv</a> -->
              <!-- / -->
              <!-- <a href="https://kenembanisi.github.io/">arXiv</a>
              / -->
              <!-- <a href="https://kenembanisi.github.io/">project page</a> -->
              <p></p>
              <p>Enabling safe and intuitive assistive navigation of telepresence robots using haptic feedback and reciprocal velocity obstacles (RVO)</p>
            </td>


          <!-- MP learning publication 2 -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/mp_learning2.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Natural Driver Control Motion Primitives for Computational Human Driver Modeling</papertitle>
              <br>
              <em>Kenechukwu C. Mbanisi</em>,  
              <a href="https://www.linkedin.com/in/hide-kimpara/">Hideyuki Kimpara</a>,
              <a href="https://web.cs.wpi.edu/~michaelg/">Michael A. Gennert</a>,
              <a href="http://labs.wpi.edu/hiro/zhi-jane-li/">Zhi Li</a>
              <br>
              <!-- <em>arXiv</em>, 2021  -->
              <em>In internal review</em>
              <br>
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a href="https://users.wpi.edu/~zli11/papers/C2018_IROS_Mbanisi_DriverMotionPrimitive.pdf">arXiv</a>
              / -->
              <a href="https://www.youtube.com/watch?v=LElY1ISa9uk">video</a>
              <!-- /
              <a href="https://kenembanisi.github.io/">code</a> -->
              <p></p>
              <p>Novel application of imitation learning algorithms to model natural driver control behavior from human demonstration</p>
            </td>

          
          <!-- RoboNav -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/robonav2.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>RoboNav: Mapless Indoor Navigation using Deep Reinforcement Learning</papertitle>
              <br>
              <!-- <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
              <em>arXiv</em>, 2021 
              <br> -->
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2103.14645">arXiv</a> -->
              <!-- / -->
              <a href="https://docs.google.com/presentation/d/1A6RJ-Lwd6sobZYWkM8gACb9-oAHzP6MlmDPccWTx9v8/edit?usp=sharing">slides</a>
              /
              <a href="https://github.com/kenembanisi/RoboNav">project page</a>
              <p></p>
              <p>Applied end-to-end learning approach for dynamic collision avoidance of an autonomous mobile robot using Deep Q-Learning and DDPG algorithms.</p>
              <p>Collaborative work with Abhishek Jain, Kavit Nilesh Shah and Sanjeev Kannan</p>
            </td>


          <!-- HuMADS publication -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/humads.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Human Model-Based Active Driving System in Vehicular Dynamic Simulation</papertitle>
              <br>
              <a href="https://www.linkedin.com/in/hide-kimpara/">Hideyuki Kimpara</a>,
              <em>Kenechukwu C. Mbanisi</em>,           
              <a href="https://sites.google.com/site/dvprokhorov/">Danil Prokhorov</a>,
              <a href="https://users.wpi.edu/~jfu2/">Jie Fu</a>,
              <a href="http://labs.wpi.edu/hiro/zhi-jane-li/">Zhi Li</a>,
              <a href="https://web.cs.wpi.edu/~michaelg/">Michael A. Gennert</a>
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2020 
              <br>
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <a href="https://users.wpi.edu/~zli11/papers/J2019_Mbanisi_Human.pdf">paper</a>
              <!-- /
              <a href="https://kenembanisi.github.io/">video</a> -->
              <!-- /
              <a href="https://kenembanisi.github.io/">code</a> -->
              <p></p>
              <p>Proposed a novel model-based active driver simulation framework for investigating human-vehicle interaction in semi- and fully-autonomous vehicles</p>
            </td>


          
          <!-- Force anticipation publication -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/force_ant.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Force Anticipation and Its Potential Implications on
                Feedforward and Feedback Human Motor Control</papertitle>
                <br>
                <a href="https://www.linkedin.com/in/hide-kimpara/">Hideyuki Kimpara</a>,
                <em>Kenechukwu C. Mbanisi</em>,  
                <a href="http://labs.wpi.edu/hiro/zhi-jane-li/">Zhi Li</a>,
                <a href="https://www.wpi.edu/people/faculty/ktroy">Karen L. Troy</a>,
                <a href="https://sites.google.com/site/dvprokhorov/">Danil Prokhorov</a>,
                <a href="https://web.cs.wpi.edu/~michaelg/">Michael A. Gennert</a>
                <br>
              <em>Human Factors</em>, 2020
              <br>
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <a href="https://journals.sagepub.com/doi/full/10.1177/0018720819900842">paper</a>
              <!-- /
              <a href="https://kenembanisi.github.io/">video</a> -->
              <!-- /
              <a href="https://kenembanisi.github.io/">code</a> -->
              <p></p>
              <p>This work investigates the effects of human force anticipation on human motor control by conducting an experimental 
                load-pushing study with diverse combinations of informed and actual loading weights.</p>
            </td>


          
          <!-- Surgical robot project -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/surgical.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Surgical Robotics using an Industrial Manipulator Robot</papertitle>
              <br>
              <a href="https://www.youtube.com/watch?v=EwtT7nBfjyI">video</a>
              /
              <a href="https://github.com/kenembanisi/surgical_industrial_arm">code</a>
              /
              <a href="https://github.com/kenembanisi/surgical_industrial_arm/blob/master/doc/final_report.pdf">report</a>
              <p></p>
              <p>We developed a mechanism to enable mounting a da Vinci Research Kit insertion tool on an ABB Industrial robot.
                Also, we developed software packages consisting of kinematics, trajectory generation and teleoperation functionality.</p>
              <p>Collaborative work with Yan Wang, Yuqi Jiang, Tianyu Cheng, and Abhijeet Thakan</p>
            </td>
          
          
          <!-- MP learning 1 publication -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/mp-iros.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Coordinated Vehicle Maneuver Motion Primitives from Human Demonstration</papertitle>
              <br>
              <em>Kenechukwu C. Mbanisi</em>,
              <a href="https://www.linkedin.com/in/hide-kimpara/">Hideyuki Kimpara</a>,
              <a href="https://www.altecresearch.com/tess-meier.html">Tess B. Meier</a>,
              <a href="https://web.cs.wpi.edu/~michaelg/">Michael A. Gennert</a>,
              <a href="http://labs.wpi.edu/hiro/zhi-jane-li/">Zhi Li</a>
              <br>
              <em>IROS</em>, 2018
              <br>
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <a href="https://users.wpi.edu/~zli11/papers/C2018_IROS_Mbanisi_DriverMotionPrimitive.pdf">paper</a>
              <!-- /
              <a href="https://kenembanisi.github.io/">video</a> -->
              <!-- /
              <a href="https://kenembanisi.github.io/">code</a> -->
              <p></p>
              <p>We propose an integrated human-vehicle interaction simulation framework which learns vehicle 
                maneuver motion primitives from human drivers, and uses them to compose natural and contextual driving motions.</p>
            </td>


          <!-- Fatigue -->
          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div> -->
                <img src='images/fatigue.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Assessment of Physical Fatigue in Robot Teleoperation during Complex
                Motion Coordination Tasks</papertitle>
              <br>
              <em>Kenechukwu C. Mbanisi</em>,
              <a href="https://www.linkedin.com/in/alexandravaliton/"> Alexandra R. Valiton</a>,
              <a href="https://www.linkedin.com/in/renee-dorer-1044ba167/">Renee K. Dorer</a>,
              <a href="http://labs.wpi.edu/hiro/zhi-jane-li/">Zhi Li</a>
              <br>
              Poster presentation at <a href="https://sites.google.com/site/humansafetyandcomfortiros2018/accepted-papers"><em>IROS 2018 Workshop on Robotic Co-Workers 4.0</em></a>
              <br>
              <!-- <a href="http://nerf.live">project page</a> -->
              <!-- / -->
              <a href="https://users.wpi.edu/~zli11/papers/W2018_IROS_Mbanisi_PhysicalFatigue.pdf">paper</a>
              <!-- /
              <a href="https://kenembanisi.github.io/">video</a> -->
              <!-- /
              <a href="https://kenembanisi.github.io/">code</a> -->
              <p></p>
              <p> We proposed a study to evaluate teleoperation interfaces in the performance of complex motion coordination tasks on the basis of operator physical fatigue.</p>
            </td>


          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ArbalaezCVPR2014.jpg" alt="ArbalaezCVPR2014" width="160" height="120" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1M0wijHY134F9ETBgO8mjeuKUSblTRLG0/view?usp=sharing">
                <papertitle>Multiscale Combinatorial Grouping</papertitle>
              </a>
              <br>
              <a href="http://www.cs.berkeley.edu/~arbelaez/">Pablo Arbel&aacuteez</a>, <a href="http://imatge.upc.edu/web/people/jordi-pont-tuset">Jordi Pont-Tuset</a>, <strong>Jonathan T. Barron</strong>, <a href="http://imatge.upc.edu/web/ferran">Ferran Marqu&eacutes</a>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
              <br>
              <em>CVPR</em>, 2014
              <br>
              <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
              <a href="data/ArbelaezCVPR2014.bib">bibtex</a>
              <p>This paper is subsumed by <a href="#MCG_journal">our journal paper</a>.</p>
            </td>
          </tr> -->

        </tbody></table>

        <!-- Teaching and Outreach Experience -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Teaching & Outreach Experiences</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <!-- Pan-African Robotics Competition (PARC) -->
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/parc.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://parcrobotics.org/"><papertitle> 2021 Pan-African Robotics Competition (PARC)</papertitle>
            </a>
            <p>In 2021, I am leading the advanced category (undergraduate & graduate teams) of PARC with a focus on developing navigation software for a autonomous delivery robot.
              Check the <a href="https://parcrobotics.org/vlp/engineers/competition-overview/">competition documentation</a>  for more details.
            </p>
          </td>

        
        <!-- Cobots For Kids -->
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/cobots.jpg' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arminstitute.org/projects/cobots-for-kids/"><papertitle> Cobots For Kids Program </papertitle>
            </a>
            <p>This program aims at inspiring and training the next generation of robotics and advanced manufacturing workforce. With support from the ARM Institute and M2I2, we
              run 7-week programs for middle school students on using collaborative robots, CNC machines and CAD software. </p>
            <p>Paper abstract summarising our efforts has been accepted for ASEE 2021.</p>
            </p>
          </td>


        <!-- Robotics TA -->
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/wpi_robotics.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle> Graduate Teaching Assistant at WPI</papertitle>
            <p>I have served as a graduate teaching assistant for undergraduate courses such as Introduction to Robotics (RBE 1001), Control Engineering (ES 3011). I helped develop the
              robotics lab sessions for the control engineering course in Spring 2021.
            </p>
          </td>



        <!-- MS4SSA -->
        <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/ms4ssa.jpg' width="160">
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://www.wpi.edu/offices/provost/interdisciplinary-groups/global-initiatives/ms4ssa"><papertitle> Maths and Science for Sub-Saharan Africa (MS4SSA) </papertitle>
            </a>
            <p>The program's goal is to improve quality of STEM education at secondary level across sub-Saharan Africa by empowering secondary school STEM teachers through training and
              access to resources. I served as a robotics curriculum developer and facilitator.
            </p>
          </td>

        
      
        <!-- Footnote -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code and style cloned from  <a href="https://jonbarron.info/">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
